{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from simtk import unit\n",
    "from simtk import openmm\n",
    "import numpy as np\n",
    "from sys import stdout\n",
    "from openmmtools import integrators\n",
    "import random\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defines system for use in BG and in MD simulation, can create from scratch as commented out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pdb = app.PDBFile('ala2_fromURL.pdb')\n",
    "# topology = pdb.getTopology()\n",
    "# positions = pdb.getPositions(asNumpy=True).value_in_unit(unit.nanometer)\n",
    "\n",
    "# ff = app.ForceField('amber99sbildn.xml',\"amber96_obc.xml\")\n",
    "# system = ff.createSystem(\n",
    "#     topology=topology, \n",
    "#     removeCMMotion=True,\n",
    "#     nonbondedMethod=app.NoCutoff,\n",
    "#     constraints=app.HBonds, \n",
    "#     rigidWater=True\n",
    "#     )\n",
    "\n",
    "with open('ala2_xml_system.txt') as f:\n",
    "    xml = f.read()\n",
    "system = openmm.XmlSerializer.deserialize(xml)\n",
    "#platform 2 = CUDA\n",
    "platform = openmm.Platform.getPlatform(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting up generator\n",
    "import torch\n",
    "\n",
    "device = \"cuda:3\" if torch.cuda.is_available() else \"cpu\"\n",
    "dtype = torch.float32\n",
    "# a context tensor to send data to the right device and dtype via '.to(ctx)'\n",
    "ctx = torch.zeros([], device=device, dtype=dtype)\n",
    "\n",
    "#need to load a dataset for dimensions of BG and to set up Mixed Coordinate Transform which requires data as an argument\n",
    "import mdtraj\n",
    "dataset = mdtraj.load('TSFtraj.dcd', top='ala2_fromURL.pdb')\n",
    "\n",
    "import numpy as np\n",
    "rigid_block = np.array([6, 8, 9, 10, 14])\n",
    "z_matrix = np.array([\n",
    "    [0, 1, 4, 6],\n",
    "    [1, 4, 6, 8],\n",
    "    [2, 1, 4, 0],\n",
    "    [3, 1, 4, 0],\n",
    "    [4, 6, 8, 14],\n",
    "    [5, 4, 6, 8],\n",
    "    [7, 6, 8, 4],\n",
    "    [11, 10, 8, 6],\n",
    "    [12, 10, 8, 11],\n",
    "    [13, 10, 8, 11],\n",
    "    [15, 14, 8, 16],\n",
    "    [16, 14, 8, 6],\n",
    "    [17, 16, 14, 15],\n",
    "    [18, 16, 14, 8],\n",
    "    [19, 18, 16, 14],\n",
    "    [20, 18, 16, 19],\n",
    "    [21, 18, 16, 19]\n",
    "])\n",
    "\n",
    "def dimensions(dataset):\n",
    "        return np.prod(dataset.xyz[0].shape)\n",
    "dim = dimensions(dataset)\n",
    "\n",
    "#system setup, probably need to write a function to do this\n",
    "# from simtk import openmm\n",
    "# with open('ala2_xml_system.txt') as f:\n",
    "#     xml = f.read()\n",
    "# system = openmm.XmlSerializer.deserialize(xml)\n",
    "from bgflow.distribution.energy.openmm import OpenMMBridge, OpenMMEnergy\n",
    "temperature = 300.0 * unit.kelvin\n",
    "collision_rate = 1.0 / unit.picosecond\n",
    "timestep = 4.0 * unit.femtosecond\n",
    "integrator = integrators.LangevinIntegrator(temperature=temperature,collision_rate=collision_rate,timestep=timestep)\n",
    "energy_bridge = OpenMMBridge(system, integrator, n_workers=1)\n",
    "target_energy = OpenMMEnergy(int(dim), energy_bridge)\n",
    "\n",
    "#setting up training_data argument for MixedCoordinateTransform - not sure how much effect this has\n",
    "n_train = len(dataset)//2\n",
    "n_test = len(dataset) - n_train\n",
    "permutation = np.random.permutation(n_train)\n",
    "all_data = dataset.xyz.reshape(-1, dimensions(dataset))\n",
    "training_data = torch.tensor(all_data[permutation]).to(ctx)\n",
    "test_data = torch.tensor(all_data[permutation + n_train]).to(ctx)\n",
    "\n",
    "import bgflow as bg\n",
    "\n",
    "dim_cartesian = len(rigid_block) * 3 - 6\n",
    "dim_bonds = len(z_matrix)\n",
    "dim_angles = dim_bonds\n",
    "dim_torsions = dim_bonds\n",
    "\n",
    "#set up coordinate transform layer\n",
    "coordinate_transform = bg.MixedCoordinateTransformation(\n",
    "    data=training_data, \n",
    "    z_matrix=z_matrix,\n",
    "    fixed_atoms=rigid_block,\n",
    "    keepdims=dim_cartesian, \n",
    "    normalize_angles=True,\n",
    ").to(ctx)\n",
    "\n",
    "#setting up prior distribution\n",
    "dim_ics = dim_bonds + dim_angles + dim_torsions + dim_cartesian\n",
    "mean = torch.zeros(dim_ics).to(ctx) \n",
    "# passing the mean explicitly to create samples on the correct device\n",
    "prior = bg.NormalDistribution(dim_ics, mean=mean)\n",
    "\n",
    "split_into_ics_flow = bg.SplitFlow(dim_bonds, dim_angles, dim_torsions, dim_cartesian)\n",
    "\n",
    "#defining RealNVP\n",
    "class RealNVP(bg.SequentialFlow):\n",
    "    \n",
    "    def __init__(self, dim, hidden):\n",
    "        self.dim = dim\n",
    "        self.hidden = hidden\n",
    "        super().__init__(self._create_layers())\n",
    "    \n",
    "    def _create_layers(self):\n",
    "        dim_channel1 =  self.dim//2\n",
    "        dim_channel2 = self.dim - dim_channel1\n",
    "        split_into_2 = bg.SplitFlow(dim_channel1, dim_channel2)\n",
    "        \n",
    "        layers = [\n",
    "            # -- split\n",
    "            split_into_2,\n",
    "            # --transform\n",
    "            self._coupling_block(dim_channel1, dim_channel2),\n",
    "            bg.SwapFlow(),\n",
    "            self._coupling_block(dim_channel2, dim_channel1),\n",
    "            # -- merge\n",
    "            bg.InverseFlow(split_into_2)\n",
    "        ]\n",
    "        return layers\n",
    "        \n",
    "    def _dense_net(self, dim1, dim2):\n",
    "        return bg.DenseNet(\n",
    "            [dim1, *self.hidden, dim2],\n",
    "            activation=torch.nn.ReLU()\n",
    "        )\n",
    "    \n",
    "    def _coupling_block(self, dim1, dim2):\n",
    "        return bg.CouplingFlow(bg.AffineTransformer(\n",
    "            shift_transformation=self._dense_net(dim1, dim2),\n",
    "            scale_transformation=self._dense_net(dim1, dim2)\n",
    "        ))\n",
    "\n",
    "#setting up normalising flow composed of RealNVP followed by coordinate transform\n",
    "n_realnvp_blocks = 5\n",
    "layers = []\n",
    "\n",
    "for i in range(n_realnvp_blocks):\n",
    "    layers.append(RealNVP(dim_ics, hidden=[128, 128, 128]))\n",
    "layers.append(split_into_ics_flow)\n",
    "layers.append(bg.InverseFlow(coordinate_transform))\n",
    "\n",
    "flow = bg.SequentialFlow(layers).to(ctx)\n",
    "\n",
    "#loading trained model into empty\n",
    "flow.load_state_dict(torch.load('modelTSFtraj_xmlsystem_20000KLL.pt'))\n",
    "\n",
    "#setting up generator\n",
    "generator = bg.BoltzmannGenerator(\n",
    "    flow=flow,\n",
    "    prior=prior,\n",
    "    target=target_energy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generator_new = bg.BoltzmannGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getbg_positions():    \n",
    "    bg_positions_tensor, dlogp_tensor = generator.sample(1,with_dlogp=True)\n",
    "    bg_positions = bg_positions_tensor.cpu().detach().numpy().reshape(22,3)\n",
    "    dlogp = dlogp_tensor.cpu().detach().numpy()\n",
    "    return bg_positions, dlogp\n",
    "#print(bg_positions, dlogp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getbias(positions):\n",
    "    torch_positions = torch.tensor(positions.value_in_unit(unit.nanometer).reshape(-1,66)).to(ctx)\n",
    "    z, dlogp_inverse_tensor = flow.forward(torch_positions,inverse=True)\n",
    "    dlogp_inverse = dlogp_inverse_tensor.cpu().detach().numpy()\n",
    "    return -dlogp_inverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#unit.BOLTZMANN_CONSTANT_kB is in units of J/K\n",
    "kb = unit.BOLTZMANN_CONSTANT_kB * unit.AVOGADRO_CONSTANT_NA\n",
    "kt = kb * temperature\n",
    "kt = kt.value_in_unit(unit.kilojoule_per_mole)\n",
    "beta = 1/kt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cycles = 100\n",
    "MDsteps = 1000\n",
    "BGmoves = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Setting up MD and initialising\n",
    "\n",
    "pdb = openmm.app.PDBFile('ala2_fromURL.pdb')\n",
    "topology = pdb.getTopology()\n",
    "positions = pdb.getPositions(asNumpy=True).value_in_unit(unit.nanometer)\n",
    "\n",
    "md_temperature = 1000 * unit.kelvin\n",
    "md_collision_rate = 1.0 / unit.picosecond\n",
    "md_timestep = 1.0 * unit.femtosecond\n",
    "\n",
    "integrator = integrators.LangevinIntegrator(temperature=md_temperature,collision_rate=md_collision_rate,timestep=md_timestep)\n",
    "#integrator.setConstraintTolerance(0.00001)\n",
    "#integrator = openmm.VerletIntegrator(timestep)\n",
    "properties_dict = {}\n",
    "properties_dict[\"DeviceIndex\"] = \"1\"\n",
    "simulation = openmm.app.Simulation(topology, system, integrator,platform,platformProperties=properties_dict)\n",
    "simulation.context.setPositions(positions)\n",
    "simulation.minimizeEnergy()\n",
    "simulation.context.setVelocitiesToTemperature(temperature)\n",
    "#simulation.reporters.append(openmm.app.StateDataReporter(stdout, reportInterval=100, step=True, potentialEnergy=True,temperature=True,kineticEnergy=True))\n",
    "simulation.step(100000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##NO Bias\n",
    "accept_counter = []\n",
    "for x in range(cycles):\n",
    "    print('cycle',x)\n",
    "    simulation.step(MDsteps)\n",
    "    current_state = simulation.context.getState(getEnergy=True,getPositions=True)\n",
    "    current_positions = current_state.getPositions(asNumpy=True)\n",
    "    current_total_energy = current_state.getKineticEnergy() + current_state.getPotentialEnergy()\n",
    "    print('MD_end_energy',current_total_energy)\n",
    "    for y in range(BGmoves):  \n",
    "        integrator = integrators.LangevinIntegrator(temperature=md_temperature,collision_rate=md_collision_rate,timestep=md_timestep)\n",
    "        bgsimulation = openmm.app.Simulation(topology,system,integrator,platform,platformProperties=properties_dict)\n",
    "        bg_positions, bias_new = getbg_positions()\n",
    "        bgsimulation.context.setPositions(bg_positions)\n",
    "        bgsimulation.context.setVelocitiesToTemperature(md_temperature)\n",
    "        new_state = bgsimulation.context.getState(getEnergy=True)\n",
    "        new_total_energy = new_state.getKineticEnergy() + new_state.getPotentialEnergy()\n",
    "        energy_change = (new_total_energy - current_total_energy).value_in_unit(unit.kilojoule_per_mole)\n",
    "        acceptance_prob = min(1,(np.exp(-beta*energy_change)))\n",
    "        if random.random() < acceptance_prob:\n",
    "            print('accept new conformation')\n",
    "            print('accepted BG energy',new_total_energy)\n",
    "            new_checkpoint = bgsimulation.context.createCheckpoint()\n",
    "            simulation.context.loadCheckpoint(new_checkpoint)\n",
    "            accept_counter.append(y)\n",
    "            break\n",
    "        else:\n",
    "            print('rejected BG energy',y,new_total_energy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##WITH BIAS\n",
    "# accept_counter = []\n",
    "# for x in range(cycles):\n",
    "#     print('cycle',x)\n",
    "#     simulation.step(MDsteps)\n",
    "#     current_state = simulation.context.getState(getEnergy=True,getPositions=True)\n",
    "#     current_positions = current_state.getPositions(asNumpy=True)\n",
    "#     bias_current = getbias(current_positions)\n",
    "#     current_total_energy = current_state.getKineticEnergy() + current_state.getPotentialEnergy()\n",
    "#     print('MD_end_energy',current_total_energy)\n",
    "#     for y in range(BGmoves):  \n",
    "#         integrator = integrators.LangevinIntegrator(temperature=md_temperature,collision_rate=md_collision_rate,timestep=md_timestep)\n",
    "#         bgsimulation = openmm.app.Simulation(topology,system,integrator,platform,platformProperties=properties_dict)\n",
    "#         bg_positions, bias_new = getbg_positions()\n",
    "#         bgsimulation.context.setPositions(bg_positions)\n",
    "#         bgsimulation.context.setVelocitiesToTemperature(md_temperature)\n",
    "#         new_state = bgsimulation.context.getState(getEnergy=True)\n",
    "#         new_total_energy = new_state.getKineticEnergy() + new_state.getPotentialEnergy()\n",
    "#         #print('new_tot_energy',new_total_energy)\n",
    "#         energy_change = (new_total_energy - current_total_energy).value_in_unit(unit.kilojoule_per_mole)\n",
    "#         acceptance_prob = min(1,(np.exp(-beta*energy_change)*bias_new/bias_current))\n",
    "#         if random.random() < acceptance_prob:\n",
    "#             print('accept new conformation')\n",
    "#             print('accepted BG energy',new_total_energy)\n",
    "#             new_checkpoint = bgsimulation.context.createCheckpoint()\n",
    "#             simulation.context.loadCheckpoint(new_checkpoint)\n",
    "#             accept_counter.append(y)\n",
    "#             break\n",
    "#         else:\n",
    "#             print('rejected BG energy',y,new_total_energy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.average(accept_counter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_positions = current_state.getPositions(asNumpy=True)\n",
    "torch_positions = torch.tensor(current_positions.value_in_unit(unit.nanometer).reshape(-1,66)).to(ctx)\n",
    "\n",
    "z = flow.forward(torch_positions,inverse=True)\n",
    "x_out = flow.forward(z[0])\n",
    "z_2 = flow.forward(x_out[0],inverse=True)\n",
    "x_2 = flow.forward(z_2[0])\n",
    "z_3 = flow.forward(x_out[0],inverse=True)\n",
    "x_3 = flow.forward(z_3[0])\n",
    "print('initial_x',torch_positions)\n",
    "print('z 1',z)\n",
    "print('x_out',x_out)\n",
    "print('z 2',z_2)\n",
    "print('x_2',x_2)\n",
    "print('z 3',z_3)\n",
    "print('x_3',x_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bg_positions, z = generator.sample(1, with_latent=True)\n",
    "z_from_inverse = flow.forward(bg_positions, inverse=True)\n",
    "\n",
    "print(bg_positions)\n",
    "print(z)\n",
    "print(z_from_inverse)\n",
    "\n",
    "x_new = flow.forward(z_from_inverse[0])\n",
    "x_fromlatent = flow.forward(z)\n",
    "\n",
    "print(x_new)\n",
    "print(x_fromlatent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BG_cartesian = generator.sample(1000)\n",
    "\n",
    "MD300K_traj = mdtraj.load('300K.dcd',top='ala2_fromURL.pdb',stride=100)\n",
    "MD300K_cartesian = torch.tensor(MD300K_traj.xyz.reshape(-1,66)).to(ctx)\n",
    "\n",
    "MD3000K_traj = mdtraj.load('3000K.dcd',top='ala2_fromURL.pdb',stride=100)\n",
    "MD3000K_cartesian = torch.tensor(MD3000K_traj.xyz.reshape(-1,66)).to(ctx)\n",
    "\n",
    "BG3000K_traj = mdtraj.load('3000K_samplestraj.dcd',top='ala2_fromURL.pdb',stride=10)\n",
    "BG3000K_cartesian = torch.tensor(BG3000K_traj.xyz.reshape(-1,66)).to(ctx)\n",
    "\n",
    "MD300K_superposed_traj = MD300K_traj.superpose(MD300K_traj[0])\n",
    "MD300K_superposed_cartesian = torch.tensor(MD300K_superposed_traj.xyz.reshape(-1,66)).to(ctx)\n",
    "\n",
    "MD1000K_traj = mdtraj.load('1000K.dcd',top='ala2_fromURL.pdb',stride=40)\n",
    "MD1000K_cartesian = torch.tensor(MD1000K_traj.xyz[0:1000].reshape(-1,66)).to(ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots(figsize=(8,4))\n",
    "means = {}\n",
    "dist_from_means = {}\n",
    "cartesian_sets = {'BG 2000KLL on TSF traj': BG_cartesian,\n",
    "            #'MD300K': MD300K_cartesian,\n",
    "            #'MD1000K' : MD1000K_cartesian,\n",
    "            #'MD300K superposed' : MD300K_superposed_cartesian,\n",
    "            'MD non superposed 3000 K' : MD3000K_cartesian,\n",
    "            'BG 2000 KLL trained on superposed 3000 K' : BG3000K_cartesian\n",
    "            }\n",
    "\n",
    "names_list = list(cartesian_sets)\n",
    "for name, cartesian_data in cartesian_sets.items():\n",
    "    means[name] = torch.mean(cartesian_data, dim = 0)\n",
    "    dist_from_means[name] = torch.sub(cartesian_data, means[name])\n",
    "    ax.hist(dist_from_means[name].flatten().cpu().detach().numpy(), bins = 40, label=f'{name}', alpha = (1-names_list.index(name)/5))\n",
    "\n",
    "ax.legend(bbox_to_anchor = (1.04,1), loc='upper left')\n",
    "ax.set_xlabel(\"Distance from mean, Cartesian space\")\n",
    "#ax.set_ylabel(f\"Count   [#Samples / {len(cartesian_data[name].flatten())}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,4))\n",
    "latents = {}\n",
    "means = {}\n",
    "dist_from_means = {}\n",
    "cartesian_sets = {'BG 2000KLL trained on TSF traj': BG_cartesian,\n",
    "            #'MD300K': MD300K_cartesian,\n",
    "            #'MD1000K' : MD1000K_cartesian,\n",
    "            #'MD300K superposed' : MD300K_superposed_cartesian,\n",
    "            'MD non superposed 3000 K' : MD3000K_cartesian,\n",
    "            'BG 2000 KLL trained on superposed 3000 K' : BG3000K_cartesian\n",
    "            }\n",
    "\n",
    "names_list = list(cartesian_sets)\n",
    "for name, cartesian_data in cartesian_sets.items():\n",
    "    latents[cartesian_data] = flow.forward(cartesian_data,inverse=True)[0]\n",
    "    means[cartesian_data] = torch.mean(latents[cartesian_data], dim = 0)\n",
    "    dist_from_means[cartesian_data] = torch.sub(latents[cartesian_data], means[cartesian_data])\n",
    "    ax.hist(dist_from_means[cartesian_data].flatten().cpu().detach().numpy(), bins = 40, label=f'{name}', alpha = (1-names_list.index(name)/5))\n",
    "\n",
    "ax.legend(bbox_to_anchor = (1.04,1), loc='upper left')\n",
    "ax.set_xlabel(\"Distance from mean, latent space\")\n",
    "#ax.set_ylabel(f\"Count   [#Samples / {len(BG_cart_distfrommean.flatten())}]\")\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7c9d31eb73c8f3e112db66097c42d16831eaf5100aebfeaf3802cb7e3312826a"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('bgflow_env': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
